const { OpenAI } = require('openai');
const https = require('https');
const http = require('http');

class ChatGPTHandler {
    constructor() {
        this.openai = null;
        this.conversationHistory = [];
        this.maxHistoryLength = 10;
        this.screenpipeHandler = null;
    }

    initialize(apiKey) {
        if (!apiKey) {
            console.error('‚ùå OpenAI API key is required');
            return false;
        }

        try {
            this.openai = new OpenAI({ apiKey: apiKey });
            console.log('‚úÖ OpenAI client initialized');
            return true;
        } catch (error) {
            console.error('‚ùå Error initializing OpenAI client:', error);
            return false;
        }
    }

    setScreenpipeHandler(screenpipeHandler) {
        this.screenpipeHandler = screenpipeHandler;
        console.log('‚úÖ Screenpipe handler connected to ChatGPT');
    }

    async sendMessage(message, onResponse, onError) {
        if (!this.openai) {
            console.error('‚ùå OpenAI client not initialized');
            if (onError) onError('OpenAI client not initialized');
            return;
        }

        try {
            console.log('ü§ñ Sending message to ChatGPT:', message);

            // Search for relevant screenpipe context
            let screenContext = '';
            if (this.screenpipeHandler && this.screenpipeHandler.isInitialized) {
                try {
                    console.log('üîç Searching for relevant screen context...');
                    const relevantScreenshots = await this.screenpipeHandler.searchScreenshots(message, 3);
                    
                    if (relevantScreenshots && relevantScreenshots.length > 0) {
                        screenContext = this.buildScreenContext(relevantScreenshots);
                        console.log('‚úÖ Found relevant screen context');
                    } else {
                        console.log('‚ÑπÔ∏è No relevant screen context found');
                    }
                } catch (error) {
                    console.warn('‚ö†Ô∏è Error searching screen context:', error.message);
                }
            }

            // Add user message to history
            this.addToHistory('user', message);

            // Prepare messages for API call with screen context
            const messages = [
                {
                    role: "system",
                    content: this.buildSystemPrompt(screenContext)
                },
                ...this.conversationHistory
            ];

            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o-mini",
                messages: messages,
                max_tokens: 500,
                temperature: 0.7
            });

            const response = completion.choices[0].message.content;
            console.log('ü§ñ ChatGPT response:', response);

            // Add assistant response to history
            this.addToHistory('assistant', response);

            if (onResponse) {
                onResponse(response);
            }

        } catch (error) {
            console.error('‚ùå Error calling ChatGPT API:', error);
            if (onError) {
                onError(error.message || 'Failed to get response from ChatGPT');
            }
        }
    }

    needsWebSearch(text) {
        const lowerText = text.toLowerCase().trim();
        const webSearchPatterns = [
            /\b(today|now|current|latest|recent|news|weather)\b/,
            /\b(price|cost|stock)\b.*\b(today|now|current)\b/,
            /\bwhat.*happening\b/,
            /\bevents.*today\b/,
            /\blatest.*update\b/,
            /\bcurrent.*status\b/,
            /\bnews\b/,
            /\bweather\b/,
            /\btime.*in\b/,
            /\bexchange.*rate\b/
        ];
        return webSearchPatterns.some(pattern => pattern.test(lowerText));
    }

    isQuestionPattern(text) {
        const lowerText = text.toLowerCase().trim();
        const questionPatterns = [
            /^what(\s+is|\s+are|\s+was|\s+were|\s+does|\s+do|\s+did|\s+'s)/,
            /^how(\s+do|\s+does|\s+did|\s+can|\s+to|\s+much|\s+many)/,
            /^why(\s+is|\s+are|\s+do|\s+does|\s+did)/,
            /^when(\s+is|\s+are|\s+was|\s+were|\s+do|\s+does|\s+did)/,
            /^where(\s+is|\s+are|\s+was|\s+were|\s+do|\s+does|\s+did)/,
            /^who(\s+is|\s+are|\s+was|\s+were)/,
            /^which(\s+is|\s+are|\s+was|\s+were)/,
            /^can\s+you(\s+tell|\s+explain|\s+describe)/,
            /^tell\s+me(\s+about)/,
            /^explain/,
            /^describe/,
            /\berror\b.*\?$/,
            /\bissue\b.*\?$/,
            /\bproblem\b.*\?$/,
            /weather/,
            /time(\s+is\s+it)?$/
        ];
        return questionPatterns.some(pattern => pattern.test(lowerText));
    }

    getQuestionAnalysisPrompt(message) {
        const lowerMessage = message.toLowerCase();
        
        if (lowerMessage.includes('error') || lowerMessage.includes('issue') || lowerMessage.includes('problem')) {
            return `TASK: Analyze the screenshot to identify and explain an error or issue.

ANALYSIS STRUCTURE:
1. **Error Identification**: What specific error/issue is visible?
2. **Context**: What application/service/system is involved?
3. **Root Cause**: What likely caused this error?
4. **Solution Steps**: Clear, numbered steps to resolve it
5. **Prevention**: How to avoid this in the future

Focus on being precise and actionable.`;
        }
        
        return `TASK: Provide a comprehensive answer using the screenshot as visual context.

RESPONSE STRUCTURE:
1. **Current Context**: What do you see in the screenshot?
2. **Direct Answer**: Address the specific question asked
3. **Additional Details**: Relevant context or related information
4. **Next Steps**: If applicable, suggest follow-up actions

Be clear, accurate, and well-structured.`;
    }

    getActionAnalysisPrompt(message) {
        return `TASK: Generate automation instructions based on the screenshot and voice command.

ANALYSIS STRUCTURE:
1. **Current State**: Describe what's visible in the screenshot
2. **User Intent**: What the user wants to accomplish  
3. **Automation Steps**: Specific, executable instructions
4. **Target Elements**: Identify specific UI elements to interact with
5. **Success Criteria**: How to verify the task completed

Provide precise, actionable automation instructions for macOS.`;
    }

    getEnhancedSystemPrompt(isQuestion, hasScreenshot, needsWebSearch) {
        if (isQuestion) {
            let basePrompt = `You are a knowledgeable AI assistant specialized in providing structured, comprehensive answers.

RESPONSE FORMAT:
- Use clear headings and bullet points
- Provide specific, actionable information
- Include examples when helpful
- Structure complex information logically`;

            if (hasScreenshot) {
                basePrompt += `\n- Analyze the screenshot carefully for visual context
- Reference specific UI elements you can see
- Explain what's happening in the interface`;
            }

            if (needsWebSearch) {
                basePrompt += `\n- Search for current, up-to-date information when needed
- Provide the most recent and accurate data available
- Include relevant context from current sources`;
            }

            basePrompt += `\n\nFor ERROR ANALYSIS specifically:
## Error Details
- **Type**: Specific error classification
- **Location**: Where the error appears
- **Message**: Exact error text if visible

## Root Cause
- **Primary Cause**: Main reason for the error
- **Contributing Factors**: Additional issues

## Solution
1. **Immediate Steps**: Quick fixes to try first
2. **Comprehensive Fix**: Complete resolution process
3. **Verification**: How to confirm it's resolved

## Prevention
- Best practices to avoid recurrence
- Monitoring or maintenance suggestions`;

            return basePrompt;
        } else {
            // Action/automation prompts remain the same
            return hasScreenshot ? 
                "You are an AI automation assistant with vision capabilities. Analyze the screenshot and voice command to generate PRECISE, CLEAR automation instructions for macOS..." :
                "You are a helpful AI assistant. Provide concise, helpful responses.";
        }
    }

    buildScreenContext(screenshots) {
        if (!screenshots || screenshots.length === 0) {
            return '';
        }

        const contextParts = screenshots.map((screenshot, index) => {
            const timestamp = new Date(screenshot.payload.timestamp).toLocaleString();
            const text = screenshot.payload.text.substring(0, 300);
            const score = (screenshot.score * 100).toFixed(1);
            
            return `Screenshot ${index + 1} (${score}% relevant, captured ${timestamp}):
Content: ${text}${screenshot.payload.text.length > 300 ? '...' : ''}`;
        });

        return `RELEVANT SCREEN CONTEXT:
${contextParts.join('\n\n')}

Use this context to provide more relevant and contextual responses. If the user is asking about something visible on their screen, reference this information. If the context isn't relevant to their question, respond normally without mentioning it.`;
    }

    buildSystemPrompt(screenContext) {
        let prompt = "You are a helpful AI assistant integrated with the user's desktop. Provide concise, helpful responses.";

        if (screenContext) {
            prompt += `\n\n${screenContext}`;
        }

        return prompt;
    }

    addToHistory(role, content) {
        this.conversationHistory.push({ role, content });
        
        if (this.conversationHistory.length > this.maxHistoryLength * 2) {
            this.conversationHistory = this.conversationHistory.slice(-this.maxHistoryLength * 2);
        }
    }

    clearHistory() {
        this.conversationHistory = [];
        console.log('üóëÔ∏è Conversation history cleared');
    }

    getHistory() {
        return this.conversationHistory;
    }
}

module.exports = ChatGPTHandler; 